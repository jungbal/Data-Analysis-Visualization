{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8sF2LWFI2cwDI6hxC58bq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. 선형 회귀 분석**\n","선형 회귀 분석(Linear Regression)은 주어진 데이터에서 입력 변수(독립 변수)와 출력 변수(종속 변수) 사이의 관계를 직선(또는 다차원에서는 평면)으로 설명하고, 새로운 입력 값에 대한 출력을 예측하는 통계 및 머신러닝 기법입니다. 예를 들어, 공부 시간(입력 변수)과 시험 점수(출력 변수) 사이의 관계를 분석해 \"공부 시간이 늘어날수록 시험 점수가 증가한다\"는 패턴을 찾아냅니다. 이 과정에서 선형 회귀는 \"Y = W X + b\"라는 수식(기울기 W와 절편 b)으로 데이터를 표현하며, 최적의 기울기와 절편을 찾기 위해 비용 함수(Cost Function)를 최소화하는 경사 하강법(Gradient Descent) 등의 알고리즘을 사용합니다. 최종적으로 선형 회귀 모델은 주어진 입력 값에 대해 가장 적합한 예측 결과를 제공합니다."],"metadata":{"id":"JG-pUYW31Bot"}},{"cell_type":"markdown","source":["# **2. 단항 선형 회귀**\n","단항 선형 회귀(Simple Linear Regression)는 하나의 독립 변수(입력 변수, X)를 사용하여 하나의 종속 변수(출력 변수, Y)를 예측하는 통계 및 머신러닝 기법입니다. 입력 변수와 출력 변수 사이의 관계를 직선(Linear Line)으로 나타내며, 데이터의 패턴을 기반으로 가장 잘 맞는 직선을 찾아내어 새로운 입력 값에 대한 출력을 예측합니다."],"metadata":{"id":"PMFj_aaP1HVG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt"],"metadata":{"id":"YQxq1gvA5zrZ","executionInfo":{"status":"ok","timestamp":1736158157680,"user_tz":-540,"elapsed":8766,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(2025)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgjT927A6l9q","executionInfo":{"status":"ok","timestamp":1736158157682,"user_tz":-540,"elapsed":11,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"8f74910f-0291-489c-ed61-c0c031d98cad"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7dafe35e7e50>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])\n","print(x_train, x_train.shape)\n","print(y_train, y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2Cbwr906tiG","executionInfo":{"status":"ok","timestamp":1736158157682,"user_tz":-540,"elapsed":10,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"23923eb2-547a-4225-8a00-4861c2fe3951"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.],\n","        [2.],\n","        [3.]]) torch.Size([3, 1])\n","tensor([[2.],\n","        [4.],\n","        [6.]]) torch.Size([3, 1])\n"]}]},{"cell_type":"code","source":["plt.figure(figsize=(6, 4))\n","plt.scatter(x_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"sebW_XO98eoF","executionInfo":{"status":"ok","timestamp":1736158157682,"user_tz":-540,"elapsed":9,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"d0af8128-2f8c-4ebc-cda4-e534bfc7d84f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7dafb8f649a0>"]},"metadata":{},"execution_count":4},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# y = wx + b\n","model = nn.Linear(1, 1) # 입력 갯수, 출력 갯수\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EX9EzpFW8xaX","executionInfo":{"status":"ok","timestamp":1736158157682,"user_tz":-540,"elapsed":7,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"f4eea575-43a3-4f09-9f92-7ff4a270f47a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=1, out_features=1, bias=True)\n"]}]},{"cell_type":"code","source":["y_pred = model(x_train) #[[1], [2], [3]]\n","print(y_pred)\n","print(list(model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoNpf85V9RqM","executionInfo":{"status":"ok","timestamp":1736158157682,"user_tz":-540,"elapsed":6,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"83b65c53-d9e1-4d35-f40f-c773522f996e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.2410],\n","        [1.6109],\n","        [1.9809]], grad_fn=<AddmmBackward0>)\n","[Parameter containing:\n","tensor([[0.3699]], requires_grad=True), Parameter containing:\n","tensor([0.8711], requires_grad=True)]\n"]}]},{"cell_type":"markdown","source":["> 손실 함수(Loss Function)는 머신러닝과 딥러닝 모델이 예측한 값과 실제 값 사이의 차이를 수치적으로 나타내는 함수입니다. 모델이 학습을 통해 최적의 결과를 도출하려면 이 차이를 최소화해야 합니다. 손실 함수는 예측값과 실제값의 오차를 계산하여 하나의 숫자(스칼라 값)로 반환하며, 이 값은 비용(Cost) 또는 오차(Error)라고도 불립니다. 예를 들어, 회귀 문제에서는 주로 평균 제곱 오차(MSE, Mean Squared Error)를 사용하여 예측값과 실제값 간의 평균적인 차이를 측정하고, 분류 문제에서는 교차 엔트로피 손실(Cross-Entropy Loss)을 사용해 예측 확률 분포와 실제 레이블 분포 간의 차이를 계산합니다. 손실 함수가 반환한 값은 역전파(Backpropagation)를 통해 모델의 가중치와 편향을 조정하는 데 사용됩니다. 즉, 손실 함수는 모델이 학습 과정에서 목표로 삼아야 할 방향을 알려주는 나침반 역할을 합니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcylqtP%2FbtsLBsQ8oy1%2FbKf0GNsv0fMbdzzvkNa0V1%2Fimg.webp'>"],"metadata":{"id":"cwT_vE7m90M_"}},{"cell_type":"code","source":["((y_pred - y_train)**2).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4aHBueEG-s02","executionInfo":{"status":"ok","timestamp":1736158157682,"user_tz":-540,"elapsed":5,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"45982fc5-9db6-454e-bce0-25c35a179a3a"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7.4790, grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# mse_loss = nn.MSELoss()\n","# mse_loss(y_pred, y_train)\n","loss = nn.MSELoss()(y_pred, y_train)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8u0qujwAnWu","executionInfo":{"status":"ok","timestamp":1736158158509,"user_tz":-540,"elapsed":832,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"5b194953-7bb4-4515-ae83-7ca6ca7ba3be"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7.4790, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["> 최적화(Optimization)는 주어진 목표를 달성하기 위해 최상의 해결책(Optimal Solution)을 찾아가는 과정입니다. 머신러닝과 딥러닝에서는 주로 모델이 예측한 값과 실제 값 사이의 오차(손실 함수 값)를 최소화하는 것을 목표로 합니다. 이 과정에서 모델의 학습 가능한 파라미터(가중치와 편향)를 조정하여 손실 함수의 값을 점점 더 작게 만들어갑니다. 최적화는 주로 경사 하강법(Gradient Descent)과 같은 알고리즘을 사용해 수행되며, 손실 함수의 기울기(Gradient)를 따라가며 최저점(또는 최적점)을 찾습니다. 이 과정은 마치 산에서 가장 낮은 지점을 찾아 내려가는 것과 비슷합니다. 최적화는 단순히 손실을 줄이는 것뿐만 아니라, 학습 속도, 안정성, 과적합 방지와 같은 다양한 요소를 고려해야 하는 복합적인 과정입니다. 즉, 최적화는 모델이 데이터로부터 가장 정확하고 효율적인 예측을 할 수 있도록 파라미터를 조정하는 핵심 과정입니다."],"metadata":{"id":"BJmZpxmrBC3i"}},{"cell_type":"markdown","source":["> 경사하강법(Gradient Descent)은 머신러닝과 딥러닝 모델이 최적의 가중치(Weights)와 편향(Biases)를 찾기 위해 손실 함수(Loss Function)를 최소화하는 방법입니다. 이 알고리즘은 마치 산 꼭대기에서 출발해 가장 낮은 지점(최솟값)을 찾아 내려가는 과정과 비슷합니다. 먼저, 모델은 손실 함수의 기울기(Gradient)를 계산합니다. 이 기울기는 현재 지점에서 손실이 가장 빠르게 감소하는 방향을 나타냅니다. 이후, 모델은 기울기의 반대 방향으로 가중치와 편향 값을 조금씩 업데이트합니다. 이때 학습률(Learning Rate)은 한 번에 이동하는 \"걸음의 크기\"를 결정합니다. 학습률이 너무 크면 최적의 지점을 지나칠 수 있고, 너무 작으면 학습 속도가 매우 느려질 수 있습니다. 이 과정을 반복하면서 손실 함수 값이 점점 작아지고, 결국 최적의 가중치와 편향을 찾아내게 됩니다. 즉, 경사하강법은 모델이 더 나은 예측을 할 수 있도록 가중치를 조정해주는 핵심 최적화 알고리즘입니다.\n","\n","경사하강법은 데이터를 어떻게 나눠서 학습하느냐에 따라 배치(Batch), 확률적(Stochastic), 미니배치(Mini-Batch)로 나뉩니다.\n","\n","> 학습률(Learning Rate)은 머신러닝과 딥러닝 모델이 학습할 때 가중치(Weights)와 편향(Biases)를 얼마나 크게 조정할지를 결정하는 하이퍼파라미터입니다. 경사하강법(Gradient Descent)과 같은 최적화 알고리즘에서 손실 함수(Loss Function)의 기울기(Gradient)를 따라 최적의 가중치를 찾아갈 때, 학습률은 한 번의 업데이트에서 이동하는 \"걸음의 크기\"를 의미합니다. 학습률이 너무 크면 최적의 가중치를 지나쳐 버리거나 학습이 불안정해질 수 있고, 너무 작으면 학습 속도가 매우 느려져 최적값에 도달하기 어려울 수 있습니다. 따라서 적절한 학습률을 선택하는 것은 모델의 학습 속도와 최적화 성능을 결정하는 중요한 요소입니다. 일반적으로 고정된 학습률을 사용하기도 하지만, 상황에 따라 학습률을 점진적으로 줄이거나 동적으로 조정하는 방법(예: Adam, Step Decay, Cyclical Learning Rate 등)이 사용되기도 합니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdFPhqQ%2FbtsLB2q1has%2FzVPvcaVxyYbGb1lpVGdJpk%2Fimg.png'>"],"metadata":{"id":"-sH5tgCEBIHC"}},{"cell_type":"markdown","source":["> SGD(Stochastic Gradient Descent, 확률적 경사하강법)는 모델의 가중치(Weights)와 편향(Biases)를 최적화하기 위해 손실 함수(Loss Function)의 기울기(Gradient)를 따라 반복적으로 업데이트하는 가장 기본적인 옵티마이저입니다. 일반적인 경사하강법은 전체 데이터셋을 한 번에 사용해 기울기를 계산하지만, SGD는 무작위로 선택된 하나의 데이터 포인트(순수 SGD) 또는 작은 그룹(미니배치 SGD)을 사용해 기울기를 계산하고 가중치를 조정합니다. 이로 인해 학습 속도가 빨라지고 메모리 사용량이 줄어들지만, 진동이 발생할 수 있어 학습이 불안정할 수도 있습니다. PyTorch에서 SGD는 optim.SGD로 구현되며, 학습률(lr)과 모멘텀(momentum) 등의 매개변수를 통해 조정할 수 있습니다. 주로 작은 데이터셋이나 빠른 반복 학습이 필요한 경우 사용되며, 학습률이 적절하게 설정되면 강력하고 효율적인 최적화 결과를 제공합니다."],"metadata":{"id":"9XAGYCsJIRq6"}},{"cell_type":"code","source":["optimizer = optim.SGD(model.parameters(), lr=0.01)"],"metadata":{"id":"8QphgNAMIWZ5","executionInfo":{"status":"ok","timestamp":1736158164068,"user_tz":-540,"elapsed":5561,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# gradient를 초기화\n","optimizer.zero_grad()\n","# 역전파: 비용 함수를 미분하여 gradient(기울기) 계산\n","loss.backward()\n","# W와 b를 업데이트\n","optimizer.step()"],"metadata":{"id":"YwEEFIkOJKBz","executionInfo":{"status":"ok","timestamp":1736158164069,"user_tz":-540,"elapsed":5,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["list(model.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAl1lx4DJqL7","executionInfo":{"status":"ok","timestamp":1736158164069,"user_tz":-540,"elapsed":4,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"8e4a6a8c-846b-4b9b-8fe2-240b5c8cdcf1"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[0.4872]], requires_grad=True),\n"," Parameter containing:\n"," tensor([0.9188], requires_grad=True)]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 반복 학습을 통해 오차가 있는 W, b를 수정하면서 오차를 계속 줄여나감\n","# epochs: 반복 학습 횟수(에포크)\n","epochs = 1000\n","for epoch in range(epochs + 1):\n","    y_pred = model(x_train)\n","    loss = nn.MSELoss()(y_pred, y_train)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    if epoch % 100 == 0:\n","        print(f'Epoch: {epoch}/{epochs} Loss: {loss: .6f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUEdbonJJ5EZ","executionInfo":{"status":"ok","timestamp":1736158165034,"user_tz":-540,"elapsed":969,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"a6f1569e-7a58-4377-dcad-d6f7d73ee7ad"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0/1000 Loss:  5.963749\n","Epoch: 100/1000 Loss:  0.156203\n","Epoch: 200/1000 Loss:  0.096524\n","Epoch: 300/1000 Loss:  0.059646\n","Epoch: 400/1000 Loss:  0.036857\n","Epoch: 500/1000 Loss:  0.022776\n","Epoch: 600/1000 Loss:  0.014074\n","Epoch: 700/1000 Loss:  0.008697\n","Epoch: 800/1000 Loss:  0.005374\n","Epoch: 900/1000 Loss:  0.003321\n","Epoch: 1000/1000 Loss:  0.002052\n"]}]},{"cell_type":"code","source":["print(list(model.parameters())) # W: 1.9475, b: 0.1193"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hY54HdVxLEFJ","executionInfo":{"status":"ok","timestamp":1736158165034,"user_tz":-540,"elapsed":5,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"b7764fd6-eb31-4f23-e70e-75dd3516fa73"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[1.9475]], requires_grad=True), Parameter containing:\n","tensor([0.1193], requires_grad=True)]\n"]}]},{"cell_type":"code","source":["# y = Wx + b\n","# y = 1.9475*x + 0.1193\n","# y = 1.9475*5 + 0.1193\n","1.9475*5 + 0.1193"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFpBb6elLOi8","executionInfo":{"status":"ok","timestamp":1736158165035,"user_tz":-540,"elapsed":5,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"71f5f572-19a4-40f3-b295-ec440de1af58"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.856800000000002"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["x_test = torch.FloatTensor([[5]])\n","y_pred = model(x_test)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALghP__QL6fi","executionInfo":{"status":"ok","timestamp":1736158165035,"user_tz":-540,"elapsed":4,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"63c6a514-fd70-4c3d-a2ed-5c07a4da079b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[9.8569]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["# **3. 다중 선형 회귀**\n","다중 선형 회귀(Multiple Linear Regression)는 여러 개의 독립 변수(입력 변수)를 사용해 하나의 종속 변수(출력 변수)를 예측하는 통계 및 머신러닝 기법입니다. 단순 선형 회귀가 하나의 독립 변수와 하나의 종속 변수 간의 선형 관계를 설명하는 반면, 다중 선형 회귀는 두 개 이상의 입력 변수가 출력 변수에 어떻게 영향을 미치는지를 분석합니다. 이 관계는 수식으로 표현되며, 예를 들어 Y=W1X1+W2X2+...+WnXn+b와 같이 나타납니다. 여기서 Y는 예측 값, X1,X2,...Xn ​은 입력 변수, W1,W2,...Wn ​은 각 변수의 가중치, b는 절편입니다. 다중 선형 회귀는 입력 변수들이 독립적이고, 종속 변수와 선형 관계를 가진다는 가정 하에 작동하며, 주로 경제학, 의료, 마케팅 등 다양한 분야에서 복합적인 요인의 영향을 분석하고 예측하는 데 사용됩니다."],"metadata":{"id":"O7bEjT3rMEBE"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"],"metadata":{"id":"EqdFT42yMsWL","executionInfo":{"status":"ok","timestamp":1736158509322,"user_tz":-540,"elapsed":352,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OZKB0qBHHWU","executionInfo":{"status":"ok","timestamp":1736158581303,"user_tz":-540,"elapsed":327,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"d79e5885-f855-4f9b-aa18-0b59b3648d18"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cpu\n"]}]},{"cell_type":"code","source":["X_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70],\n","                             [85, 90, 88],\n","                             [78, 85, 82]]).to(device)\n","\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142], [175], [155]]).to(device)"],"metadata":{"id":"K7xHis9EHY7l","executionInfo":{"status":"ok","timestamp":1736158687103,"user_tz":-540,"elapsed":348,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["print(X_train, X_train.shape)\n","print(y_train, y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJmt5MAVHywJ","executionInfo":{"status":"ok","timestamp":1736158762334,"user_tz":-540,"elapsed":348,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"334c1601-4a61-4cbd-c80f-6694e6651ca4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 73.,  80.,  75.],\n","        [ 93.,  88.,  93.],\n","        [ 89.,  91.,  90.],\n","        [ 96.,  98., 100.],\n","        [ 73.,  66.,  70.],\n","        [ 85.,  90.,  88.],\n","        [ 78.,  85.,  82.]]) torch.Size([7, 3])\n","tensor([[152.],\n","        [185.],\n","        [180.],\n","        [196.],\n","        [142.],\n","        [175.],\n","        [155.]]) torch.Size([7, 1])\n"]}]},{"cell_type":"code","source":["# y = W1x1 + W2x2 + W3x3 + b\n","model = nn.Linear(3, 1).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSdiTR__IAY1","executionInfo":{"status":"ok","timestamp":1736158847235,"user_tz":-540,"elapsed":352,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"e7d65cdd-4dff-4b09-fa84-02946daf7af9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=3, out_features=1, bias=True)\n"]}]},{"cell_type":"code","source":["# optimizer = optim.SGD(model.parameters(), lr=0.00001)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","loss_fn = nn.MSELoss()\n","epochs = 1000"],"metadata":{"id":"LHWMjEhFIZ1z","executionInfo":{"status":"ok","timestamp":1736159922581,"user_tz":-540,"elapsed":316,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["for epoch in range(epochs + 1):\n","\n","    y_pred = model(X_train)\n","\n","    loss = loss_fn(y_pred, y_train)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    if epoch % 100 == 0:\n","        print(f'Epoch: {epoch}/{epochs}, Loss: {loss.item():.6f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rG4MxYXJtB_","executionInfo":{"status":"ok","timestamp":1736159938784,"user_tz":-540,"elapsed":1010,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"4ff74cdc-6db1-4a06-dc72-4a2b6a07d7ce"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0/1000, Loss: 5.555117\n","Epoch: 100/1000, Loss: 5.519960\n","Epoch: 200/1000, Loss: 5.485106\n","Epoch: 300/1000, Loss: 5.440427\n","Epoch: 400/1000, Loss: 5.388330\n","Epoch: 500/1000, Loss: 5.330417\n","Epoch: 600/1000, Loss: 5.268044\n","Epoch: 700/1000, Loss: 5.202287\n","Epoch: 800/1000, Loss: 5.134008\n","Epoch: 900/1000, Loss: 5.066279\n","Epoch: 1000/1000, Loss: 5.004326\n"]}]},{"cell_type":"markdown","source":[">  Adam(Adaptive Moment Estimation)은 경사하강법(Gradient Descent)을 개선한 최적화 알고리즘으로, 머신러닝과 딥러닝 모델 학습에서 널리 사용됩니다. Adam은 SGD(Stochastic Gradient Descent)의 단점을 보완하기 위해 개발되었으며, 각 가중치(Weight)와 편향(Bias)마다 다른 학습률(Learning Rate)을 적용해 더욱 효율적이고 안정적으로 최적화를 수행합니다. 이 알고리즘은 기울기의 평균(1차 모멘트, First Moment)과 기울기 제곱의 평균(2차 모멘트, Second Moment)을 모두 활용하여 학습률을 동적으로 조정합니다. 학습 초반에는 빠르게 학습하고, 학습 후반에는 안정적으로 수렴하도록 설계되었습니다. Adam은 계산 비용이 적고, 메모리 사용량이 효율적이며, 하이퍼파라미터를 따로 튜닝하지 않아도 대부분의 문제에서 좋은 성능을 보여줍니다."],"metadata":{"id":"hWVsEpB9KLcs"}},{"cell_type":"markdown","source":["<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdAJop6%2FbtsLCmWW0xy%2FKiEDaQmgfRtjPnxL6SNdH1%2Fimg.png'>"],"metadata":{"id":"FQPL-oSBK0g_"}},{"cell_type":"code","source":["for param in model.parameters():\n","    print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxbfyXlWLjox","executionInfo":{"status":"ok","timestamp":1736159941700,"user_tz":-540,"elapsed":367,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"63ea6264-7e2f-45ac-835c-cf9929b8019d"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[1.5365, 0.4565, 0.0767]], requires_grad=True)\n","Parameter containing:\n","tensor([-5.0808], requires_grad=True)\n"]}]},{"cell_type":"code","source":["# y = 0.5499 + 0.4637 + 0.9841 + -0.5439\n","x_test = torch.FloatTensor([[93, 93, 93]]).to(device)\n","y_pred = model(x_test)\n","print(f\"\\n새로운 입력 데이터 {x_test.tolist()}의 예측 결과: {y_pred.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2gKjM3rL3IJ","executionInfo":{"status":"ok","timestamp":1736160010886,"user_tz":-540,"elapsed":327,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"b7d2b46b-0c10-443e-c5ac-63d482d6b26b"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","새로운 입력 데이터 [[93.0, 93.0, 93.0]]의 예측 결과: 187.4041\n"]}]}]}