{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO911sDN28gcHe9E6hNnDxR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. 생성형 AI**\n","생성형 AI는 주어진 데이터를 학습하고 이를 바탕으로 새로운 콘텐츠를 만들어내는 인공지능 기술입니다. 예를 들어, 이런 AI는 사람처럼 글을 쓰거나 그림을 그릴 수 있습니다. 기본적으로 많은 데이터를 분석해 패턴을 배우고, 그 패턴을 사용해 새로운 것을 창작하는 것입니다. 그래서 질문에 대한 답변이나 창의적인 글쓰기, 이미지 생성 등 다양한 작업을 할 수 있도록 도와줍니다."],"metadata":{"id":"-Prszb17n7Hr"}},{"cell_type":"markdown","source":["# **2. LLM와 SLM**\n"],"metadata":{"id":"JlxGvk2BoGUY"}},{"cell_type":"markdown","source":["### 2-1. LLM(Large Language Model)\n","LLM은 대형 언어 모델을 의미합니다. 이 모델은 매우 큰 데이터셋을 기반으로 학습되며, 수억에서 수조 개의 파라미터를 가지고 있습니다. 주로 딥러닝 기술을 활용하며, 자연어 처리(NLP) 작업에서 뛰어난 성능을 발휘합니다. LLM은 인간의 언어를 이해하고 생성하는 데 매우 뛰어난 능력을 보이며, 예를 들어 텍스트 생성, 번역, 질문 응답, 요약 등 다양한 작업을 처리할 수 있습니다.\n","\n","예) ChatGPT, Bloom, Gemini, LLaMa, Mistral 등"],"metadata":{"id":"U8of7X6MpbsI"}},{"cell_type":"markdown","source":["### 2-2. SLM(Small Language Model)\n","SLM은 소형 언어 모델을 의미하며, LLM과 비교하여 상대적으로 작은 크기의 모델입니다. SLM은 적은 수의 파라미터를 가지고 있으며, 특정 작업에 대해 최적화된 모델입니다. 이런 모델은 대형 모델보다 계산 자원이 적게 들고, 빠른 속도와 적은 메모리를 요구하지만, 성능은 LLM에 비해 다소 제한적일 수 있습니다.\n","\n","예) T5-Small, GPT-NeoX, ALBERT, MobileBERT 등"],"metadata":{"id":"Q5LFgNO4pmXh"}},{"cell_type":"markdown","source":["# **4. 토큰**\n","토큰은 모델이 처리하는 텍스트의 작은 단위입니다. 하나의 토큰은 단어, 부분적인 단어, 또는 심지어 공백이나 구두점일 수 있습니다. 예를 들어, \"나는 학교에 간다\"라는 문장은 5개의 토큰(나는, 학교, 에, 간다)으로 나눠질 수 있습니다. GPT 모델은 텍스트를 처리할 때 이 토큰들을 기반으로 학습하고, 예측을 생성합니다."],"metadata":{"id":"BqgEqadbpaq6"}},{"cell_type":"markdown","source":["### 4-1. 토큰은 과금 단위로 사용\n","- https://openai.com/api/pricing/\n","\n","- https://platform.openai.com/tokenizer"],"metadata":{"id":"9ntP_qXgfSf5"}},{"cell_type":"markdown","source":["### 4-2. 토큰화\n","토큰화(Tokenization)는 자연어 처리(NLP)에서 텍스트를 모델이 이해할 수 있는 작은 단위인 '토큰'으로 분리하는 과정입니다. 토큰은 대개 단어, 부분 단어, 구두점, 공백 등으로 구성될 수 있습니다. 이 과정은 언어 모델이 텍스트를 효과적으로 이해하고 처리할 수 있도록 돕습니다. 토큰화 방법은 문장을 어떻게 나누느냐에 따라 다르며, 각 방법은 모델이 텍스트를 어떻게 처리할지에 큰 영향을 미칩니다."],"metadata":{"id":"7Hp0JHxZfak-"}},{"cell_type":"markdown","source":["### 4-3. 토큰화 방법\n","* 단어 단위 토큰화 (Word-level Tokenization): 문장을 단어 단위로 나눕니다.\n","예) \"나는 학교에 간다\" → [\"나는\", \"학교에\", \"간다\"]\n","* 서브워드 단위 토큰화 (Subword-level Tokenization): 단어를 더 작은 단위로 나눕니다. 주로 길고 복잡한 단어를 나누는 데 사용됩니다.\n","예)  \"학교에\" → [\"학\", \"교\", \"에\"]\n","* 문자 단위 토큰화 (Character-level Tokenization): 문장을 하나하나의 문자로 나눕니다.\n","예)  \"학교\" → [\"학\", \"교\"]\n","* BPE (Byte Pair Encoding): 자주 등장하는 문자 쌍을 하나의 서브워드로 합치는 방법입니다.\n","예)  \"low\"와 \"est\"라는 단어가 있을 때, \"low\"와 \"est\"를 합쳐서 \"lowest\"와 같은 서브워드를 만드는 방식입니다. 자주 나오는 문자 쌍을 합쳐서 더 효율적인 토큰을 만들 수 있습니다. 이 방식은 주로 GPT와 같은 모델에서 사용됩니다."],"metadata":{"id":"bKMWe2KOfffZ"}},{"cell_type":"markdown","source":["# **5. GPT API 이용한 간단한 실습**"],"metadata":{"id":"3LaJbkhZiVX-"}},{"cell_type":"markdown","source":["### 5-1. .env\n",".env 파일은 환경 변수(Environment Variables) 를 저장하는 파일로, 주로 애플리케이션의 설정 정보나 비밀 키(secret key), 데이터베이스 비밀번호 등의 중요한 정보를 코드와 분리하여 관리하기 위해 사용됩니다. 이렇게 중요한 정보를 코드 안에 하드코딩하는 대신 .env 파일에 저장하고, 이를 코드에서 읽어오는 방식으로 보안과 유연성을 높일 수 있습니다."],"metadata":{"id":"2J6F-kRmioZp"}},{"cell_type":"code","source":["!pip install python-dotenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3MtoD6pkm4p","executionInfo":{"status":"ok","timestamp":1732879119552,"user_tz":-540,"elapsed":3119,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"fab4c9ba-843b-4d10-f1ab-7545b739d5a9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"]}]},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAFzoPIKpOa6","executionInfo":{"status":"ok","timestamp":1732879132634,"user_tz":-540,"elapsed":3291,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"c5eba0c3-946e-4bdb-944c-db92d195a8bd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"]}]},{"cell_type":"code","source":["import os\n","from openai import OpenAI\n","from dotenv import load_dotenv"],"metadata":{"id":"pVNgwQj-ko6F","executionInfo":{"status":"ok","timestamp":1732879240104,"user_tz":-540,"elapsed":310,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["load_dotenv()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWd3SnHWon7E","executionInfo":{"status":"ok","timestamp":1732879014161,"user_tz":-540,"elapsed":496,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"7de1430c-d648-4ac2-ddcd-e93665af238c"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["client = OpenAI(\n","    api_key = os.getenv('API_KEY')\n",")"],"metadata":{"id":"uCgDpEhyo1VO","executionInfo":{"status":"ok","timestamp":1732879243072,"user_tz":-540,"elapsed":267,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["response = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[{\"role\":\"user\", \"content\":\"Hello bukbuk, how are you?\"}]\n",")"],"metadata":{"id":"YTlF0nnqpVmi","executionInfo":{"status":"ok","timestamp":1732879446656,"user_tz":-540,"elapsed":1240,"user":{"displayName":"이정원","userId":"17805342290468030966"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEizUSG-qeu_","executionInfo":{"status":"ok","timestamp":1732879471704,"user_tz":-540,"elapsed":288,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"f703d555-9ab5-485b-fa8b-836763c1e49e"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatCompletion(id='chatcmpl-AYtNSYjeT8MnLPDEnRI03Z0dVHmEM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you with anything you need. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732879386, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=35, prompt_tokens=16, total_tokens=51, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["response.choices[0].message.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"XhEUahzjqlFo","executionInfo":{"status":"ok","timestamp":1732879533980,"user_tz":-540,"elapsed":493,"user":{"displayName":"이정원","userId":"17805342290468030966"}},"outputId":"5a15c3e6-e4a9-4eba-ef5f-a6d11cc8c300"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you with anything you need. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"8ZBQQ3Qbq0Ph"},"execution_count":null,"outputs":[]}]}